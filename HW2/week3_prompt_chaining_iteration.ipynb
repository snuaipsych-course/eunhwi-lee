{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_YHrLNQKBWz"
   },
   "source": [
    "# Reasoning practice\n",
    "\n",
    "Set up your API in .env file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "wya4ifAZKAPy",
    "outputId": "cec1e909-b05b-4a2d-dc7e-eefa39ae479c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758445105.741364 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "학생의 풀이가 맞는지 단계별로 설명하겠습니다.\n",
       "\n",
       "**1. 문제 이해:**\n",
       "\n",
       "문제가 요구하는 것은 태양광 발전 시설의 첫 해 운영 비용을 시설 면적(제곱피트)의 함수로 나타내는 것입니다.  주어진 정보는 다음과 같습니다:\n",
       "\n",
       "*   땅값: 제곱피트당 250\n",
       "*   유지 보수 비용: 제곱피트당 10\n",
       "\n",
       "**2. 학생 풀이 분석:**\n",
       "\n",
       "학생의 풀이에는 몇 가지 오류가 있습니다.\n",
       "\n",
       "*   **땅값:** 학생은 땅값을 100x라고 계산했습니다. 문제에서 땅값은 제곱피트당 250이라고 주어졌으므로, 땅값은 250x가 되어야 합니다.\n",
       "*   **태양광 패널 비용:** 문제에는 태양광 패널 비용에 대한 정보가 없습니다. 따라서 이 비용은 계산에 포함되어서는 안 됩니다.\n",
       "*   **유지 보수 비용:** 학생은 유지 보수 비용을 100,000 + 100x라고 계산했습니다. 문제에서 유지 보수 비용은 제곱피트당 10이라고 주어졌으므로, 유지 보수 비용은 10x가 되어야 합니다. 100,000이라는 고정 비용은 문제에 제시되지 않았습니다.\n",
       "\n",
       "**3. 올바른 풀이:**\n",
       "\n",
       "*   x를 시설 면적 (제곱피트)라고 합시다.\n",
       "*   땅값: 250x\n",
       "*   유지 보수 비용: 10x\n",
       "*   총 비용: 250x + 10x = 260x\n",
       "\n",
       "따라서, 첫 해 운영 비용은 260x입니다.\n",
       "\n",
       "**4. 결론:**\n",
       "\n",
       "학생의 풀이는 땅값, 태양광 패널 비용, 유지 보수 비용 계산에 오류가 있어 틀렸습니다. 올바른 답은 260x입니다.\n",
       "\n",
       "**한국어 요약:**\n",
       "\n",
       "학생의 풀이는 틀렸습니다. 문제에서 주어진 정보를 잘못 해석하고, 불필요한 비용을 추가했습니다. 땅값은 제곱피트당 250이므로 250x로 계산해야 하고, 유지 보수 비용은 제곱피트당 10이므로 10x로 계산해야 합니다. 태양광 패널 비용은 문제에 언급되지 않았으므로 포함해서는 안 됩니다. 따라서, 올바른 답은 260x입니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    # Colab 환경에서 API 키 불러오기\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    # 로컬 환경에서는 dotenv 사용\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        # 현재 노트북이 있는 디렉토리에서 .env 파일 찾기\n",
    "        load_dotenv()  # 현재 디렉토리 또는 상위 디렉토리에서 .env 자동 탐색\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    \n",
    "    # 환경변수에서 키 읽기\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "# API 키 설정\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"  # 또는 \"gemini-1.5-flash\", \"gemini-1.5-pro\"\n",
    "\n",
    "# 모델 초기화\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# Gemini 호출 함수 (안전한 텍스트 추출 포함)\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    try:\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        # 응답 텍스트 추출\n",
    "        if response.text:\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            return \"(No text returned.)\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "# --- 프롬프트 (예시: 학생 풀이 채점) ---\n",
    "prompt = \"\"\"\n",
    "Determine if the student's solution is correct or not. \n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need help working out the financials.\n",
    "- Land costs 250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost me a flat 10 / square foot\n",
    "What is the total cost for the first year of operations as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\n",
    "Explain your reasoning step by step in Korean.\n",
    "\"\"\"\n",
    "\n",
    "#Explain your reasoning step by step in Korean 도 프롬프트 끝단에 추가해보기 \n",
    "\n",
    "# --- 실행 ---\n",
    "response = call_gemini(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMQXOyqgL3Og"
   },
   "source": [
    "Other tasks\n",
    "\n",
    "### [문제 1] 조건부 확률 (베이즈) 채점 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "J_lxM2oWL2RC",
    "outputId": "859d6f85-4ae4-4b08-b918-a76de2ac36f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758445284.651000 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 분석 및 해설\n",
       "\n",
       "**학생의 답변:** 틀렸습니다.\n",
       "\n",
       "**올바른 계산 (베이즈 정리 사용):**\n",
       "\n",
       "1. **사전 확률:** 질병 유병률은 1%이므로 P(Disease) = 0.01, P(NoDisease) = 0.99 입니다.\n",
       "2. **민감도 및 특이도:** 민감도는 90%이므로 P(Positive|Disease) = 0.9, 특이도는 90%이므로 P(Negative|NoDisease) = 0.9 입니다. 따라서 P(Positive|NoDisease) = 1 - 0.9 = 0.1 입니다.\n",
       "3. **베이즈 정리 적용:** P(Disease|Positive) = [P(Positive|Disease) * P(Disease)] / [P(Positive|Disease) * P(Disease) + P(Positive|NoDisease) * P(NoDisease)] = (0.9 * 0.01) / (0.9 * 0.01 + 0.1 * 0.99) = 0.009 / (0.009 + 0.099) = 0.009 / 0.108 = 0.0833 (약 8.33%) 입니다.\n",
       "\n",
       "따라서, 양성 판정을 받은 사람이 실제로 질병을 가지고 있을 확률은 약 8.33% 입니다.\n",
       "\n",
       "**흔한 인지적 오류 설명:**\n",
       "\n",
       "학생은 기저율 무시 오류를 범했는데, 이는 질병의 낮은 유병률을 고려하지 않고 검사의 정확도만을 맹신하여 실제 질병을 가지고 있을 확률을 과대평가하는 오류입니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== [문제 1] 조건부 확률 (베이즈) 채점 예시 ==================\n",
    "# 이 셀은 독립 실행 가능하도록 구성했습니다. (설정 + 함수 + 프롬프트 + 실행)\n",
    "# 과제 지시: 학생의 풀이가 맞는지 평가하세요. (조건부 확률/검사 양성 시 질병 확률)\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        # 현재 디렉토리에서 .env 파일 자동 탐색\n",
    "        load_dotenv()\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# --- 안전한 호출 함수 (resp.text가 None일 때 대비) ---\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    try:\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            return \"(No text returned.)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# --- 프롬프트 (조건부 확률 과제) ---\n",
    "# 상황: 질병 유병률 1%, 검사 민감도 90%, 특이도 90%.\n",
    "# 질문: 검사 양성일 때 실제로 질병일 확률 P(Disease|Positive)?\n",
    "# 오답 예시: 단순히 90%라고 주장하는 베이즈 오류(기저율 무시).\n",
    "\n",
    "#Determine if the student's solution is correct or not.\n",
    "\n",
    "prompt = \"\"\"\n",
    "Question:\n",
    "A disease has a 1% prevalence in the population. A diagnostic test has 90% sensitivity\n",
    "(P(Positive|Disease)=0.9) and 90% specificity (P(Negative|NoDisease)=0.9).\n",
    "If a person tests positive, what is P(Disease|Positive)?\n",
    "\n",
    "Answer in Korean\n",
    "\n",
    "Student's Solution:\n",
    "Because the test is 90% accurate, P(Disease|Positive) is 90%.\n",
    "\n",
    "Task:\n",
    "- State whether the student's answer is correct or incorrect.\n",
    "- Provide a brief correct calculation using Bayes' rule in plain English.\n",
    "- Give a one-sentence explanation of the common cognitive mistake involved (e.g., base-rate neglect).\n",
    "\"\"\"\n",
    "\n",
    "# --- 실행 ---\n",
    "response = call_gemini(prompt, thinking=1) #thinking = 1로 해보고 비교하기\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제 2] 휴리스틱/연합오류(결합오류; Conjunction Fallacy) 채점 예시\n",
    "\n",
    "1. 단순히 프롬프트 결과를 보려면 채점 예시 없이 실행하고 결과 확인\n",
    "\n",
    "2. 프롬프트 체이닝을 보려면 학생의 답을 임의로 입력하고 학생 채점 결과도 같이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "Zi9ka2gnL2Ts",
    "outputId": "0cfeed5b-c3fc-43a6-b2f0-0e3b2e8ceabe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758445306.395207 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Judgment:** Incorrect\n",
       "\n",
       "**Explanation:** The conjunction rule states that the probability of two events occurring together (A and B) cannot be higher than the probability of either event occurring alone (P(A and B) ≤ P(A)). Therefore, it is always more probable that Linda is simply a bank teller than that she is a bank teller *and* a feminist.\n",
       "\n",
       "**Heuristic:** The representativeness heuristic leads people to judge the probability of an event based on how similar it is to a stereotype or mental image."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()  # 현재 디렉토리에서 .env 파일 자동 탐색\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# --- 안전한 호출 함수 ---\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    try:\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            return \"(No text returned.)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# --- 프롬프트 (결합오류 과제) ---\n",
    "# 상황: 대표성 휴리스틱으로 유명한 Linda 문제 변형. '둘 다' 사건이 단독 사건보다 확률이 더 크다고 판단하는 오류.\n",
    "prompt = \"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question (Conjunction Fallacy):\n",
    "Linda is described as deeply concerned with social justice and active in community issues.\n",
    "Which is more probable?\n",
    "A) Linda is a bank teller.\n",
    "B) Linda is a bank teller and a feminist.\n",
    "\n",
    "Student's Answer:\n",
    "B) is more probable.\n",
    "\n",
    "Task:\n",
    "- Judge the student's answer as correct or incorrect.\n",
    "- Provide a short explanation referencing the conjunction rule (P(A and B) ≤ P(A)).\n",
    "- Briefly name the heuristic involved (e.g., representativeness) in one sentence.\n",
    "\"\"\"\n",
    "\n",
    "# --- 실행 ---\n",
    "response = call_gemini(prompt, thinking=0)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "j8XGUiDRL2Vp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758445943.037354 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "학생의 답은 **틀렸습니다**.\n",
       "\n",
       "Reward Prediction Error (RPE)는 실제 보상(r)에서 예상 보상(V(s))을 뺀 값입니다. 즉, RPE = r - V(s) = 2 - 5 = -3 입니다.\n",
       "\n",
       "학생은 실제 보상과 예상 보상을 더하는 실수를 했습니다. RPE는 예상과 실제의 차이를 나타내므로 빼야 합니다.\n",
       "\n",
       "학생이 RPE의 정의를 혼동한 것 같습니다. RPE 계산 공식을 명확히 이해하도록 반복 학습이 필요합니다. 예를 들어, \"만약 예상 점수가 10점이고 실제 받은 점수가 7점이라면 RPE는 얼마일까요?\"와 같은 추가 질문을 통해 이해도를 높일 수 있습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== [문제 3] DIY 실습용 템플릿 (직접 문제/풀이 작성) ==================\n",
    "# 이 셀은 학생이 직접  주제를 정하고,\n",
    "# 문제/학생 답안을 채워 넣어 채점 프롬프트를 완성하도록 구성했습니다.\n",
    "# 아래 TODO들을 자신의 주제로 바꾼 뒤 실행하세요.\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()  # 현재 디렉토리에서 .env 파일 자동 탐색\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# --- 안전한 호출 함수 ---\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    try:\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text.strip()\n",
    "        else:\n",
    "            return \"(No text returned.)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# === TODO: 아래 세 블록을 자신의 주제로 교체하세요 ===\n",
    "DIY_QUESTION = \"\"\"\n",
    "A smoker in a quitting program expects a reward of 5 points for resisting a cigarette (expected value V(s)=5).\n",
    "However, in this trial the participant receives only 2 points as actual reward (r=2).\n",
    "\n",
    "Question:\n",
    "What is the reward prediction error (RPE) in this case?\n",
    "\"\"\"\n",
    "\n",
    "DIY_STUDENT_SOLUTION = \"\"\"\n",
    "I think the RPE is +7, because r + V(s) = 2 + 5 = 7.\n",
    "\"\"\"\n",
    "\n",
    "DIY_TASK_INSTRUCTIONS = \"\"\"\n",
    "Task:\n",
    "- State whether the student's answer is correct or incorrect.\n",
    "- Provide the correct calculation of RPE in plain language (use Korean, only use English for key terms).\n",
    "- Briefly explain why the error occurred.\n",
    "- Keep feedback within 5–8 lines.\n",
    "- Suggest possible teaching strategies for the student to improve their understanding. If needed, generate a possible feedback message or additional quiz questions for the student.\n",
    "\"\"\"\n",
    "\n",
    "# --- 프롬프트 생성 ---\n",
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "{DIY_QUESTION}\n",
    "\n",
    "Student's Solution:\n",
    "{DIY_STUDENT_SOLUTION}\n",
    "\n",
    "{DIY_TASK_INSTRUCTIONS}\n",
    "\"\"\"\n",
    "\n",
    "# --- 실행 (필요 시 reasoning을 켜고 싶다면 thinking=1~4 정도로 조절) ---\n",
    "response = call_gemini(prompt, thinking=1)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpPCWC78GQ4x"
   },
   "source": [
    "[optional] Example of prompt chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3HKgeQbAvoL",
    "outputId": "eb47f758-b3b0-4e19-e483-e4ef99c78dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Explanation ===\n",
      "Imagine your mind as a bustling office.\n",
      "\n",
      "**Sensory Memory** is like a fleeting glance at a document – you briefly see everything (e.g., a flash of a car's color as it speeds by), but it's gone in seconds unless you pay attention.\n",
      "\n",
      "**Short-Term/Working Memory** is your desk's \"inbox\" – you can actively hold a few items and manipulate them (like remembering a phone number just long enough to dial it, or mentally calculating a tip). It's temporary and limited.\n",
      "\n",
      "**Long-Term Memory** is the vast filing cabinet.\n",
      "*   **Episodic Memory** stores personal \"episodes\" – like remembering your last birthday party or what you ate for breakfast.\n",
      "*   **Semantic Memory** holds general facts and knowledge – knowing that Paris is the capital of France or what a \"dog\" is.\n",
      "*   **Procedural Memory** is \"muscle memory\" – knowing *how* to ride a bike, tie your shoes, or type without thinking. These are skills you perform automatically. \n",
      "\n",
      "=== Step 2: Quiz Questions ===\n",
      "Here are 3 quiz questions based on the explanation:\n",
      "\n",
      "---\n",
      "\n",
      "**Question 1**\n",
      "Which type of memory is most like a fleeting glance at a document, holding a lot of information for only a few seconds before it's gone unless you pay attention?\n",
      "\n",
      "a) Short-Term Memory\n",
      "b) Long-Term Memory\n",
      "c) Sensory Memory\n",
      "d) Working Memory\n",
      "\n",
      "**Difficulty:** Easy\n",
      "**Type:** MCQ\n",
      "\n",
      "---\n",
      "\n",
      "**Question 2**\n",
      "You are trying to remember a new recipe you just read, actively holding the ingredients and steps in your mind as you gather them. Which type of memory are you primarily using in this scenario, and why is it limited?\n",
      "\n",
      "**Difficulty:** Medium\n",
      "**Type:** Short-Answer\n",
      "\n",
      "---\n",
      "\n",
      "**Question 3**\n",
      "Identify the specific type of Long-Term Memory being used in each of the following scenarios:\n",
      "\n",
      "a) Remembering the exact moment you learned to ride a bicycle without training wheels.\n",
      "b) Knowing that the Earth revolves around the Sun.\n",
      "c) Automatically typing on a keyboard without looking at your fingers.\n",
      "\n",
      "**Difficulty:** Hard\n",
      "**Type:** Short-Answer \n",
      "\n",
      "=== Step 3: Answer Key ===\n",
      "Here's the short answer key:\n",
      "\n",
      "**Question 1**\n",
      "c) Sensory Memory\n",
      "\n",
      "**Question 2**\n",
      "Working Memory. It's limited because it can only hold a small amount of information (typically 7 +/- 2 items) for a short duration while actively manipulating it.\n",
      "\n",
      "**Question 3**\n",
      "a) Episodic Memory\n",
      "b) Semantic Memory\n",
      "c) Procedural Memory\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# (1) Instructor Demo: Prompt Chaining\n",
    "# ============================================\n",
    "\n",
    "# Step 1: 기억의 종류 설명\n",
    "explanation = call_gemini(\n",
    "    \"Explain major types of memory (sensory, short-term/working, long-term: episodic, semantic, procedural) \"\n",
    "    \"for intro psychology students in about 120 words with daily-life examples.\"\n",
    ")\n",
    "print(\"=== Step 1: Explanation ===\")\n",
    "print(explanation, \"\\n\")\n",
    "\n",
    "# Step 2: 설명을 기반으로 퀴즈 질문 만들기\n",
    "quiz = call_gemini(\n",
    "    f\"Create 3 quiz questions for students based on this explanation. \"\n",
    "    f\"Mix MCQ and short-answer, and tag difficulty (Easy/Med/Hard).\\n\\nExplanation:\\n{explanation}\"\n",
    ")\n",
    "print(\"=== Step 2: Quiz Questions ===\")\n",
    "print(quiz, \"\\n\")\n",
    "\n",
    "# Step 3: 퀴즈 정답 만들기\n",
    "answers = call_gemini(\n",
    "    f\"Provide a short answer key (1–2 lines each) for the following quiz questions:\\n\\n{quiz}\"\n",
    ")\n",
    "print(\"=== Step 3: Answer Key ===\")\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xALLPuwNGWAJ"
   },
   "source": [
    "DIY non-reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53HqptVuAvq_",
    "outputId": "ed9bb4b0-a28b-47ac-e35f-8204f8ad7c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== One-shot Output (non-reasoning) ===\n",
      "Here's your comprehensive response on types of memory:\n",
      "\n",
      "1) **Memory Types Explained:**\n",
      "Our memory system is a fascinating process. **Sensory memory** is the initial, fleeting capture of sensory information – like the afterimage of a bright flash or the echo of a sound. It lasts only milliseconds to a few seconds. **Short-term memory (STM)**, often used interchangeably with **working memory**, holds a small amount of information (around 7 items) for about 15-30 seconds, allowing us to actively process it, like remembering a phone number just long enough to dial. **Long-term memory (LTM)** has a vast, potentially unlimited capacity and duration. Within LTM:\n",
      "    *   **Episodic memory** stores personal experiences and events (e.g., your last birthday party).\n",
      "    *   **Semantic memory** holds general knowledge and facts (e.g., the capital of France).\n",
      "    *   **Procedural memory** stores how to do things, skills and habits (e.g., riding a bike, typing).\n",
      "\n",
      "2) **Quiz Questions:**\n",
      "\n",
      "1.  **MCQ (Easy):** Which type of memory is responsible for holding information for a very brief period, typically less than a second, allowing for initial sensory processing?\n",
      "    a) Short-term memory\n",
      "    b) Long-term memory\n",
      "    c) Sensory memory\n",
      "    d) Working memory\n",
      "\n",
      "2.  **Short-Answer (Medium):** You're trying to learn a new dance routine. Which two specific types of long-term memory are most actively involved in this process, and how do they contribute?\n",
      "\n",
      "3.  **MCQ (Hard):** A person suffering from anterograde amnesia can no longer form new episodic memories but can still recall facts learned before their injury and learn new motor skills. This suggests a dissociation between which two types of long-term memory?\n",
      "    a) Semantic and Procedural\n",
      "    b) Episodic and Semantic\n",
      "    c) Episodic and Procedural\n",
      "    d) Short-term and Long-term\n",
      "\n",
      "3) **Answer Key:**\n",
      "\n",
      "1.  **c) Sensory memory**\n",
      "2.  **Episodic memory** helps you remember the specific sequence of steps you learned in a particular class or practice session. **Procedural memory** allows you to gradually master the physical movements and coordination required for the dance,\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# (2) Student Lab: Non-chaining (One-shot)\n",
    "# ============================================\n",
    "\n",
    "oneshot_prompt = (\n",
    "    \"In one response, do ALL of the following on 'types of memory':\\n\"\n",
    "    \"1) Explain sensory, short-term/working, and long-term (episodic, semantic, procedural) with daily examples (≤150 words).\\n\"\n",
    "    \"2) Make 3 quiz questions (MCQ + short-answer, tag difficulty).\\n\"\n",
    "    \"3) Provide a short answer key.\"\n",
    ")\n",
    "\n",
    "oneshot_output = call_gemini(oneshot_prompt, thinking=0)\n",
    "print(\"=== One-shot Output (non-reasoning) ===\")\n",
    "print(oneshot_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxbQh7JSAvtF",
    "outputId": "fa170361-f90d-449a-807b-e46c00e02951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step A: Explanation ===\n",
      "Memory types include:\n",
      "\n",
      "**Sensory memory** briefly holds incoming sensory information (e.g., seeing a flash of lightning, hearing a sudden noise). It lasts only a few seconds.\n",
      "\n",
      "**Short-term memory (STM)** temporarily stores and processes limited information (around 7 items for ~30 seconds). **Working memory** is an active form of STM, allowing manipulation of information (e.g., remembering a phone number while dialing, mentally calculating a tip).\n",
      "\n",
      "**Long-term memory (LTM)** stores vast amounts of information indefinitely.\n",
      "*   **Episodic memory** stores personal experiences (e.g., your last birthday party).\n",
      "*   **Semantic memory** stores general knowledge and facts (e.g., the capital of France).\n",
      "*   **Procedural memory** stores how to do things (e.g., riding a bike, tying your shoes). \n",
      "\n",
      "=== Step B: Quiz Questions ===\n",
      "Here are 3 quiz questions based on the provided explanation, mixing MCQ and short-answer, with difficulty tags:\n",
      "\n",
      "---\n",
      "\n",
      "**Question 1 (Multiple Choice)**\n",
      "**Difficulty:** Easy\n",
      "\n",
      "Which type of memory briefly holds incoming sensory information for only a few seconds?\n",
      "\n",
      "a) Short-term memory\n",
      "b) Long-term memory\n",
      "c) Sensory memory\n",
      "d) Working memory\n",
      "\n",
      "**Correct Answer:** c) Sensory memory\n",
      "\n",
      "---\n",
      "\n",
      "**Question 2 (Short Answer)**\n",
      "**Difficulty:** Medium\n",
      "\n",
      "You are trying to remember a new recipe while actively chopping vegetables and measuring ingredients. Which specific type of memory is most actively engaged in this scenario, allowing you to manipulate the recipe information as you cook?\n",
      "\n",
      "**Correct Answer:** Working memory\n",
      "\n",
      "---\n",
      "\n",
      "**Question 3 (Multiple Choice)**\n",
      "**Difficulty:** Hard\n",
      "\n",
      "Which of the following scenarios primarily relies on **semantic memory**?\n",
      "\n",
      "a) Recalling the details of your high school graduation ceremony.\n",
      "b) Knowing how to play a musical instrument without consciously thinking about each step.\n",
      "c) Remembering that the Earth revolves around the Sun.\n",
      "d) Briefly remembering a phone number just long enough to dial it.\n",
      "\n",
      "**Correct Answer:** c) Remembering that the Earth revolves around the Sun. \n",
      "\n",
      "=== Step C: Answer Key ===\n",
      "Here's a concise answer key for the provided quiz questions:\n",
      "\n",
      "1.  **Sensory Memory:** Briefly holds incoming sensory information for a few seconds.\n",
      "2.  **Working Memory:** Actively manipulates information (like a recipe) while performing tasks (chopping, measuring).\n",
      "3.  **Semantic Memory:** Stores general knowledge and facts, such as the Earth revolving around the Sun.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# (3) Student Lab: Chaining + Reasoning\n",
    "# ============================================\n",
    "\n",
    "# Step A: 설명 (reasoning 활성)\n",
    "stepA = call_gemini(\n",
    "    \"Explain the main types of memory (sensory, short-term/working, long-term: episodic, semantic, procedural) \"\n",
    "    \"with daily examples in ~120 words.\", thinking=8\n",
    ")\n",
    "print(\"=== Step A: Explanation ===\")\n",
    "print(stepA, \"\\n\")\n",
    "\n",
    "# Step B: 퀴즈 (Step A 결과 활용)\n",
    "stepB = call_gemini(\n",
    "    f\"Based on the explanation below, create 3 quiz questions. \"\n",
    "    f\"Mix MCQ and short-answer, tag difficulty.\\n\\n{stepA}\", thinking=8\n",
    ")\n",
    "print(\"=== Step B: Quiz Questions ===\")\n",
    "print(stepB, \"\\n\")\n",
    "\n",
    "# Step C: 정답 (Step B 결과 활용)\n",
    "stepC = call_gemini(\n",
    "    f\"Provide a concise answer key (1–2 lines each) for these questions:\\n\\n{stepB}\", thinking=8\n",
    ")\n",
    "print(\"=== Step C: Answer Key ===\")\n",
    "print(stepC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibAPXiC_AvvD",
    "outputId": "c1312093-5d1a-4560-da2e-ab5bb34063fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Reasoning (if exposed) ===\n",
      "Here's a brief explanation:\n",
      "\n",
      "*   **Sensory Memory:** The initial, fleeting capture of sensory information (sight, sound, touch) for a fraction of a second to a few seconds. It's largely unconscious.\n",
      "*   **Short-Term Memory (STM):** A temporary storage system that holds a small amount of information (around 7 items) for about 15-30 seconds, unless actively rehearsed. It's where you consciously process information.\n",
      "*   **Long-Term Memory (LTM):** A vast, relatively permanent storage system for information, skills, and experiences. It has an unlimited capacity and can last for a lifetime.\n",
      "\n",
      "**Daily-Life Example:**\n",
      "\n",
      "Imagine you're looking up a new pizza place's phone number:\n",
      "\n",
      "1.  **Sensory Memory:** You glance at the phone number on the menu. For a split second, your eyes capture the entire visual image of the number, even before you consciously register it.\n",
      "2.  **Short-Term Memory:** You then focus on the digits, repeating \"555-1234\" to yourself a few times to keep it in mind while you walk to the phone. If someone distracts you before you dial, you'll likely forget it.\n",
      "3.  **Long-Term Memory:** After ordering from them many times, you no longer need to look up the number; you just *know* \"555-1234\" because it's been encoded into your long-term memory.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# (4) Student Lab: Show Model Reasoning Only\n",
    "# ============================================\n",
    "\n",
    "# reasoning trace만 보고 싶을 때: thinking=1로 요청\n",
    "# (주의: 모델/SDK 버전에 따라 reasoning 출력이 없을 수도 있음)\n",
    "\n",
    "reasoning_demo = call_gemini(\n",
    "    \"Briefly explain differences among sensory, short-term, and long-term memory with one daily-life example.\",\n",
    "    thinking=1\n",
    ")\n",
    "\n",
    "print(\"=== Model Reasoning (if exposed) ===\")\n",
    "print(reasoning_demo if reasoning_demo else \"(No reasoning output available)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JEL4m8MHKbs"
   },
   "source": [
    "DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aDnF6WKMH3Tg"
   },
   "outputs": [],
   "source": [
    "# - 각 TODO 부분에 본인이 관심 있는 주제나 프롬프트를 직접 작성한다.\n",
    "# - 모든 코드는 순서대로 실행하며, 각 단계의 출력 차이를 비교한다.\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    # Colab 환경에서 API 키 불러오기\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    # 로컬 환경에서는 dotenv 사용\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()  # 현재 디렉토리에서 .env 파일 자동 탐색\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"  # 필요 시 \"gemini-1.5-pro\"로 변경 가능\n",
    "\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# Gemini 호출 함수 (간단한 wrapper)\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    prompt: 모델에 전달할 문자열\n",
    "    thinking: reasoning budget (0=비활성, 1 이상=간단 reasoning 활성)\n",
    "    return: 모델의 출력 텍스트\n",
    "    \"\"\"\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    resp = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynZkpbpDHzw_",
    "outputId": "f6a96194-4982-4eac-bca7-345e205d99ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Reasoning Output (if exposed) ===\n",
      " ## 강화학습과 의사결정이 중독에 미치는 영향\n",
      "\n",
      "#### RLDM과 addiction의 관계\n",
      "- 정의(Definition): 강화학습(Reinforcement Learning, RL)은 에이전트가 환경과의 상호작용을 통해 보상을 최대화하는 방향으로 학습하는 방법입니다. 의사결정(Decision Making, DM)은 이러한 학습 과정을 통해 최적의 행동을 선택하는 과정입니다. 중독(Addiction)은 특정 행동이나 물질에 대한 강박적인 추구와 사용으로, 뇌의 보상 시스템을 과도하게 활성화시켜 정상적인 의사결정 과정을 방해하는 상태입니다. 강화학습 모델은 중독 행동의 기저 메커니즘을 이해하고 설명하는 데 유용하게 사용될 수 있습니다. 중독은 강화학습 관점에서 볼 때, 특정 자극(예: 약물)에 대한 보상 예측 오류(Reward Prediction Error)가 과도하게 학습되어, 그 자극을 추구하는 행동이 강화되는 과정으로 설명될 수 있습니다. 즉, 기대했던 것보다 더 큰 보상을 경험하면, 그 행동을 반복할 가능성이 높아지고, 이러한 과정이 반복되면서 중독으로 이어질 수 있습니다.\n",
      "- 핵심 수식(Key equation): 보상 예측 오류(Reward Prediction Error, RPE)는  δ = R + γV(s') - V(s) 로 표현됩니다. 여기서 R은 실제 받은 보상, γ는 할인율, V(s')는 다음 상태의 가치 함수, V(s)는 현재 상태의 가치 함수를 의미합니다.\n",
      "- 관련 뇌 영역(Relevant brain areas): 복측피개영역(Ventral Tegmental Area, VTA), 측좌핵(Nucleus Accumbens, NAc), 전전두피질(Prefrontal Cortex, PFC) 등이 중독과 관련된 주요 뇌 영역입니다. VTA는 도파민을 분비하여 NAc에 전달하고, NAc는 보상과 관련된 감정을 처리합니다. PFC는 의사결정, 충동 조절, 실행 기능 등을 담당하며, 중독 상태에서는 PFC의 기능 저하가 관찰됩니다.\n",
      "\n",
      "#### 예시(Everyday Example)\n",
      "- 상황: 흡연자가 금연을 시도하는 상황. 흡연자는 담배를 피우지 않기로 결심했지만, 스트레스를 받거나 특정 상황(예: 친구들과의 술자리)에 놓이면 담배를 피우고 싶은 강렬한 욕구를 느낍니다. 과거 흡연을 통해 얻었던 즉각적인 만족감(니코틴으로 인한 도파민 분비)이 금단 증상으로 인한 불쾌감보다 더 크게 느껴지기 때문입니다.\n",
      "- 해석: 금연 시도는 강화학습 관점에서 볼 때, 과거 흡\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 실습 1 : 모델 reasoning 보기\n",
    "# ============================================================\n",
    "\n",
    "REASONING_PROMPT = \"\"\"\n",
    "- 주제: 강화학습(Reinforcement Learning)과 의사결정(Decision making)이 중독(addiction)과 어떤 관련이 있는지 설명하세요.\n",
    "- **일상적 예시** 1개(흡연 금연 상황 등)를 포함하세요.\n",
    "- **간단 수식** 1개를 본문에 한 줄로 넣으세요.\n",
    "- 한국어로 작성하되, 핵심 용어는 영문 병기를 괄호로 함께 표기하세요.\n",
    "- 출력 형식: 아래 템플릿을 따르세요.\n",
    "\n",
    "## 출력 템플릿(Output Template)\n",
    "#### RLDM과 addiction의 관계\n",
    "- 정의(Definition): ...\n",
    "- 핵심 수식(Key equation): δ = ...\n",
    "- 관련 뇌 영역(Relevant brain areas): ...\n",
    "\n",
    "#### 예시(Everyday Example)\n",
    "- 상황: ...\n",
    "- 해석: ...\n",
    "\"\"\"\n",
    "\n",
    "reasoning_output = call_gemini(REASONING_PROMPT, thinking=1)\n",
    "print(\"=== Model Reasoning Output (if exposed) ===\\n\", reasoning_output or \"(No reasoning trace exposed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Hz22LcwjIGsc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step A: Explanation ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "## RLDM과 addiction의 관계\n",
       "\n",
       "- **정의 (Definition):** 강화학습 (Reinforcement Learning, RL)은 에이전트가 환경과의 상호작용을 통해 보상을 최대화하는 방향으로 학습하는 방법입니다. 의사결정 (Decision making)은 다양한 선택지 중에서 최적의 행동을 선택하는 과정이며, 강화학습은 이러한 의사결정 과정을 모델링하고 최적화하는 데 사용될 수 있습니다. 중독 (Addiction)은 특정 행동이나 물질에 대한 강박적인 추구와 사용을 특징으로 하는 뇌 질환입니다. 강화학습 관점에서 중독은 특정 행동이 주는 즉각적인 보상에 과도하게 집중하고, 장기적인 부정적 결과는 간과하는 학습 과정으로 해석될 수 있습니다. 즉, 중독은 비정상적인 강화학습 및 의사결정 과정의 결과로 볼 수 있습니다.\n",
       "\n",
       "- **핵심 수식 (Key equation):** 시간차 오차 (Temporal Difference error)는 강화학습에서 중요한 개념으로, 예측된 보상과 실제 보상 간의 차이를 나타내며, 학습의 방향을 결정합니다. 시간차 오차는 다음과 같이 표현할 수 있습니다: δ = R + γV(s') - V(s), 여기서 R은 보상, γ는 할인율, V(s)는 현재 상태 s의 가치, V(s')는 다음 상태 s'의 가치를 의미합니다.\n",
       "\n",
       "- **관련 뇌 영역 (Relevant brain areas):** 중독과 관련된 뇌 영역은 주로 보상 시스템 (Reward system)과 관련이 있습니다. 여기에는 복측피개영역 (Ventral Tegmental Area, VTA), 측좌핵 (Nucleus Accumbens, NAc), 전전두피질 (Prefrontal Cortex, PFC) 등이 포함됩니다. VTA는 도파민을 분비하여 NAc에 전달하고, NAc는 쾌락과 보상에 대한 감정을 처리합니다. PFC는 의사결정, 충동 조절, 실행 기능 등을 담당합니다. 중독 상태에서는 이러한 뇌 영역 간의 연결이 변화하여 보상에 대한 민감도가 증가하고, 충동 조절 능력이 저하됩니다.\n",
       "\n",
       "#### 예시 (Everyday Example)\n",
       "\n",
       "- **상황:** 흡연자가 금연을 시도하는 상황을 가정해 봅시다. 흡연은 니코틴이라는 물질을 통해 뇌의 보상 시스템을 활성화시켜 즉각적인 쾌감을 제공합니다. 금연을 시도하면 니코틴 결핍으로 인해 불쾌감, 불안, 초조함 등의 금단 증상이 나타납니다.\n",
       "\n",
       "- **해석:** 강화학습 관점에서 흡연은 '흡연 -> 쾌감'이라는 긍정적 강화 루프를\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step B: Explanation ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "## Computational Mechanisms × Clinical Features\n",
       "- Mechanism 1: **높은 할인율 (High Discount Rate, γ)**\n",
       "  - Clinical Feature: 미래의 부정적인 결과보다 즉각적인 보상을 선호하여 장기적인 건강 문제에도 불구하고 중독 물질을 계속 사용하게 됨.\n",
       "- Mechanism 2: **시간차 오차 (Temporal Difference Error) 기반의 과도한 가치 학습**\n",
       "  - Clinical Feature: 중독 물질이나 행동에 대한 예측된 보상과 실제 보상 간의 차이를 과도하게 학습하여, 중독 대상에 대한 갈망과 집착을 강화함.\n",
       "- Mechanism 3: **전전두피질 기능 저하로 인한 행동 통제 및 의사결정 능력 저하**\n",
       "  - Clinical Feature: 충동 조절 실패와 잘못된 의사결정으로 인해 중독 행동을 반복하고, 금단 증상에 취약해져 재발 가능성이 높아짐.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step C: Explanation ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "## Research Directions\n",
       "\n",
       "- **Q1: 개인별 할인율(γ)의 변동성이 중독 치료 결과에 미치는 영향은 무엇인가?**\n",
       "\n",
       "  *   **중요성:** 할인율은 개인의 의사결정 과정에 깊숙이 관여하며, 중독 행동의 지속 여부를 결정하는 핵심 요인이다. 개인별 할인율의 차이를 정확히 파악하고, 이를 치료 반응 예측 및 맞춤형 치료 전략 개발에 활용한다면, 중독 치료의 효과를 극대화할 수 있을 것이다. 특히, 인지 행동 치료(CBT)와 같은 치료법의 효과를 개인별 할인율에 맞춰 최적화하는 연구가 필요하다.\n",
       "\n",
       "- **Q2: 시간차 오차 기반 학습 과정에서 특정 뇌 영역(예: 복측 선조)의 활동 패턴 변화가 중독 심화에 미치는 인과적 영향은 무엇인가?**\n",
       "\n",
       "  *   **중요성:** 시간차 오차 기반 학습은 중독의 핵심 메커니즘 중 하나이며, 특정 뇌 영역의 활동과 밀접하게 관련되어 있다. 뇌 영상 기술(fMRI, PET)과 뇌 자극 기술(TMS, tDCS)을 결합하여, 특정 뇌 영역의 활동 변화가 중독 행동에 미치는 직접적인 영향을 규명한다면, 중독 치료를 위한 새로운 신경 조절 기술 개발의 가능성을 열 수 있다. 예를 들어, 복측 선조의 과도한 활성화를 억제하는 기술은 중독 환자의 갈망을 효과적으로 감소시킬 수 있을 것이다.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  실습 2: Chaining + Reasoning (단계별)\n",
    "# ============================================================\n",
    "from IPython.display import Markdown, display\n",
    "def show_md_block(text):\n",
    "    display(Markdown(f\"```\\n{text}\\n```\"))\n",
    "\n",
    "# Step A: DIY\n",
    "STEP_A_PROMPT = \"\"\"\n",
    "- 주제: 강화학습(Reinforcement Learning)과 의사결정(Decision making)이 중독(addiction)과 어떤 관련이 있는지 설명하세요.\n",
    "- 일상적 예시 1개(흡연 금연 상황 등)를 포함하세요.\n",
    "- 간단 수식 1개를 본문에 한 줄로 넣으세요.\n",
    "- 한국어로 작성하되, 핵심 용어는 영문 병기를 괄호로 함께 표기하세요.\n",
    "- 출력 형식:\n",
    "\n",
    "## RLDM과 addiction의 관계\n",
    "- 정의(Definition): ...\n",
    "- 핵심 수식(Key equation): δ = ...\n",
    "- 관련 뇌 영역(Relevant brain areas): ...\n",
    "#### 예시(Everyday Example)\n",
    "- 상황: ...\n",
    "- 해석: ...\n",
    "\"\"\"\n",
    "step_a = call_gemini(STEP_A_PROMPT, thinking=8)  # reasoning 활성화\n",
    "print(\"=== Step A: Explanation ===\")\n",
    "show_md_block(step_a)\n",
    "# print(\"=== Step A: Explanation ===\\n\", step_a, \"\\n\")\n",
    "\n",
    "# Step B: DIY\n",
    "STEP_B_PROMPT = f\"\"\"\n",
    "위 설명({step_a})을 바탕으로,\n",
    "- RLDM 관련 주요 computational mechanism 2–3개를 뽑아라.\n",
    "- 각 메커니즘에 대해 대응되는 중독 관련 임상적 특징(clinical feature)을 1줄로 설명하라.\n",
    "- 출력 형식:\n",
    "\n",
    "## Computational Mechanisms × Clinical Features\n",
    "- Mechanism 1: ...\n",
    "  - Clinical Feature: ...\n",
    "- Mechanism 2: ...\n",
    "  - Clinical Feature: ...\n",
    "- Mechanism 3: ...\n",
    "  - Clinical Feature: ...\n",
    "\"\"\"\n",
    "step_b = call_gemini(STEP_B_PROMPT, thinking=8)\n",
    "print(\"=== Step B: Explanation ===\")\n",
    "show_md_block(step_b)\n",
    "# print(\"=== Step B: Quiz Questions ===\\n\", step_b, \"\\n\")\n",
    "\n",
    "# Step C: DIY\n",
    "STEP_C_PROMPT = f\"\"\"\n",
    "위 메커니즘–임상 특징 매핑({step_b})을 기반으로,\n",
    "- 향후 연구 질문(Research Questions) 2개를 제시하고 각 주제의 중요성을 어필하라. 각 항목은 5줄 이내 설명으로 작성하라.\n",
    "\n",
    "## Research Directions\n",
    "- Q1: ...\n",
    "- Q2: ...\n",
    "\"\"\"\n",
    "step_c = call_gemini(STEP_C_PROMPT, thinking=8)\n",
    "print(\"=== Step C: Explanation ===\")\n",
    "show_md_block(step_c)\n",
    "# print(\"=== Step C: Answer Key ===\\n\", step_c, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4jz0bK-VnyU"
   },
   "source": [
    "## ReACT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "cTrucd7GVpP8",
    "outputId": "df1071f4-5aa2-4d3b-8587-1515d70f37a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758448062.260676 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Okay, here's how I would approach this task using the ReAct (Reasoning and Acting) framework:\n",
       "\n",
       "**User Input:** \"I'm looking for a vegetarian restaurant with outdoor seating in San Francisco.\"\n",
       "\n",
       "**ReAct Cycle:**\n",
       "\n",
       "**1.  Reasoning:**\n",
       "\n",
       "*   **Goal:** Find a vegetarian restaurant with outdoor seating in San Francisco.\n",
       "*   **Constraints:**\n",
       "    *   Must be vegetarian (no meat).\n",
       "    *   Must have outdoor seating.\n",
       "    *   Must be located in San Francisco.\n",
       "*   **Potential Actions:**\n",
       "    *   Search online for vegetarian restaurants in San Francisco.\n",
       "    *   Filter the results to show only restaurants with outdoor seating.\n",
       "    *   Ask the user clarifying questions if needed (e.g., price range, cuisine preference).\n",
       "\n",
       "**2.  Action:**\n",
       "\n",
       "*   **Action:** `search[vegetarian restaurants San Francisco outdoor seating]`\n",
       "\n",
       "**3.  Observation:**\n",
       "\n",
       "*   **(Assume the search returns the following results - this is a simulated observation):**\n",
       "    *   \"Greens Restaurant (Marina District) - Vegetarian, Outdoor Seating, $$$\"\n",
       "    *   \"Gracias Madre (Mission District) - Vegan, Outdoor Seating, $$\"\n",
       "    *   \"Souvla (Hayes Valley) - Greek, Outdoor Seating, $ (Note: While Souvla has outdoor seating, it is NOT vegetarian)\"\n",
       "    *   \"Cha-Ya (Mission District) - Vegan Japanese, Outdoor Seating, $$\"\n",
       "    *   \"Millennium (Closed)\"\n",
       "\n",
       "**4.  Reasoning:**\n",
       "\n",
       "*   **Analysis of Observation:**\n",
       "    *   The search returned several potential options.\n",
       "    *   Greens, Gracias Madre, and Cha-Ya all appear to be vegetarian/vegan and have outdoor seating.\n",
       "    *   Souvla has outdoor seating but is not vegetarian, so it can be excluded.\n",
       "    *   Millennium is closed, so it can be excluded.\n",
       "*   **Next Steps:**\n",
       "    *   Present the promising options to the user.\n",
       "    *   Ask if they have any preferences regarding cuisine or price range to narrow down the choices.\n",
       "\n",
       "**5.  Action:**\n",
       "\n",
       "*   **Action:** `respond[I found a few vegetarian restaurants in San Francisco with outdoor seating: Greens Restaurant (Marina District), Gracias Madre (Mission District), and Cha-Ya (Mission District).  Greens is vegetarian, while Gracias Madre and Cha-Ya are vegan.  Do you have a preference for cuisine (e.g., Japanese, Mexican, etc.) or price range ($, $$, $$$)?]`\n",
       "\n",
       "**Next ReAct Cycle (Based on User Response):**\n",
       "\n",
       "Let's say the user responds: \"I'd prefer something in the Mission District and not too expensive.\"\n",
       "\n",
       "**1. Reasoning:**\n",
       "\n",
       "*   **Goal:** Ref"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ReAct Prompt\n",
    "# ====== 환경 설정 ======\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# API 키 설정\n",
    "if IN_COLAB:\n",
    "    # Colab 환경에서 API 키 불러오기\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    # 로컬 환경에서는 dotenv 사용\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        env_path = Path('/Users/yoon/yoonkyung-lee/week3/workshop/.env')\n",
    "        if env_path.exists():\n",
    "            load_dotenv(env_path)\n",
    "        else:\n",
    "            load_dotenv()\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL = \"gemini-2.0-flash-exp\"  # 필요 시 \"gemini-1.5-pro\"로 변경 가능\n",
    "\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "\n",
    "# Gemini 호출 함수 (간단한 wrapper)\n",
    "def call_gemini(prompt: str, thinking: int = 0, max_tokens: int = 600, temperature: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    prompt: 모델에 전달할 문자열\n",
    "    thinking: reasoning budget (0=비활성, 1 이상=간단 reasoning 활성)\n",
    "    return: 모델의 출력 텍스트\n",
    "    \"\"\"\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    resp = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "    return resp.text\n",
    "\n",
    "# ====== ReAct 프롬프트 실행 ======\n",
    "react_prompt = \"Use ReAct to help a user find a restaurant: A user is looking for a vegetarian restaurant with outdoor seating in San Francisco. How would you approach this?\"\n",
    "\n",
    "response = call_gemini(react_prompt, thinking=1)  # reasoning 활성화\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWhml_NVV6Rw"
   },
   "source": [
    "# DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GYDb1z4_V7gh"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thought: RLDM 메커니즘 선택 및 실험 설계 계획 수립. 중독 관련 핵심 메커니즘과 검증 가능한 가설, 측정 지표, 뇌 영역을 정의.\n",
       "Action: PLAN\n",
       "Observation:\n",
       "- RLDM 메커니즘 3가지 선정 (RPE, Model-based vs Model-free 가중치, Reward sensitivity)\n",
       "- 각 메커니즘 별 가설, 행동/fMRI 측정 지표, 예상 뇌 영역 정의\n",
       "- 혼란 변수 및 완화책 고려\n",
       "- 요약 및 다음 단계 작성\n",
       "\n",
       "Thought: 각 메커니즘에 대한 구체적인 가설, 측정 지표, 뇌 영역 설정. 중독 행동과 관련된 신경 메커니즘을 명확히 연결.\n",
       "Action: DESIGN\n",
       "Observation:\n",
       "- Mechanism 1: Reward Prediction Error (RPE)\n",
       "    - 가설: 중독자는 일반인에 비해 보상 예측 오차에 대한 학습률이 높을 것이다. (Higher learning rate for RPE in addicts)\n",
       "    - Behavioral: 강화 학습 과제 수행 시 보상 획득 확률 변화에 따른 반응 속도 및 선택 패턴 분석. (Reaction time and choice patterns in reinforcement learning task)\n",
       "    - fMRI: 강화 학습 과제 수행 시 ventral striatum의 활성화 정도 분석. (Ventral striatum activation during reinforcement learning)\n",
       "    - Brain Areas: Ventral Striatum, VTA\n",
       "- Mechanism 2: Model-based vs Model-free 가중치 (Model-based vs Model-free weight)\n",
       "    - 가설: 중독자는 일반인에 비해 model-free 학습 시스템에 더 의존적일 것이다. (Addicts rely more on model-free learning)\n",
       "    - Behavioral: 2단계 의사 결정 과제 수행 시 model-based/model-free 전략 사용 비율 분석. (Ratio of model-based/model-free strategies in two-step decision task)\n",
       "    - fMRI: 2단계 의사 결정 과제 수행 시 prefrontal cortex 및 striatum 활성화 패턴 분석. (Prefrontal cortex and striatum activation patterns during two-step decision task)\n",
       "    - Brain Areas: Prefrontal Cortex, Dorsolateral Striatum\n",
       "- Mechanism 3: Reward Sensitivity (보상 민감도)\n",
       "    - 가설: 중독자는 일반인에 비해 보상 자극에 대한 주관적 가치가 더 높게 평가될 것이다. (Higher subjective value for reward stimuli in addicts)\n",
       "    - Behavioral: 보상 자극 평가 과제 수행 시 보상에 대한 주관적 가치 평가 점수 비교. (Subjective value rating for reward stimuli)\n",
       "    - fMRI: 보상 자극 제시 시 orbitofrontal cortex 활성화 정도 분석. (Orbitofrontal cortex activation during reward presentation)\n",
       "    - Brain Areas: Orb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "react_prompt = \"\"\"\n",
    "You are a research assistant. Use a compact ReAct style to reason and act. \n",
    "Do NOT reveal long chain-of-thought; give only brief rationale (1–2 lines) per step.\n",
    "\n",
    "TASK:\n",
    "- 중독(addiction) 맥락에서 RLDM 메커니즘 2–3개(RPE, model-based vs model-free 가중치, reward sensitivity)를 선정하라.\n",
    "- 각 메커니즘에 대해 (1) 검증 가능한 가설 1개, (2) behavioral + fMRI 측정지표 2개, (3) 예상 뇌 영역 2개를 제안하라.\n",
    "- 간단 수식 1개(예: δ = r + γ·V(s′) − V(s)) 포함.\n",
    "- 혼란변수 2–3개와 완화책 제시.\n",
    "- 마지막에 5–8줄 요약과 next actions 2개.\n",
    "\n",
    "FORMAT (print exactly in this order):\n",
    "Thought: (why these steps? 1–2 lines, Korean with English key terms)\n",
    "Action: PLAN\n",
    "Observation: 3–5 bullets of the plan\n",
    "\n",
    "Thought: (why this design? 1–2 lines)\n",
    "Action: DESIGN\n",
    "Observation: \n",
    "- Mechanism 1: (가설 / measures / brain areas)\n",
    "- Mechanism 2: (가설 / measures / brain areas)\n",
    "- Mechanism 3: (optional)\n",
    "\n",
    "Thought: (why compute? 1 line)\n",
    "Action: COMPUTE\n",
    "Observation: δ = r + γ·V(s′) − V(s)  # brief equation only\n",
    "\n",
    "Thought: (why these risks? 1 line)\n",
    "Action: CRITIQUE\n",
    "Observation: \n",
    "- Pitfall → Mitigation\n",
    "- Pitfall → Mitigation\n",
    "- Pitfall → Mitigation\n",
    "\n",
    "Thought: (why this structure? 1 line)\n",
    "Action: WRITE\n",
    "Observation:\n",
    "## 요약(Summary)\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "#### Next actions\n",
    "- ...\n",
    "- ...\n",
    "\"\"\"\n",
    "\n",
    "response = call_gemini(react_prompt, thinking=1)  # reasoning 활성화\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpGsSilkWf_O"
   },
   "source": [
    "# Compare through tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "hzeR-egSWiPp",
    "outputId": "7fc689bf-f4ce-42cc-95fc-3c5489afb0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Running Task: Logical Deduction...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758450200.034728 59803079 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 gemini-1.5-pro ...\n",
      "\n",
      "📝 Running Task: Long-Context Understanding...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gemini-1.5-pro ...\n",
      "\n",
      "📝 Running Task: Mathematical Proof...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gemini-1.5-pro ...\n",
      "\n",
      "📝 Running Task: Medical diagnosis...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gemini-1.5-pro ...\n",
      "\n",
      "📝 Running Task: Legal case...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gemini-1.5-pro ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gemini-2.0-flash-exp</th>\n",
       "      <th>gemini-1.5-pro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logical Deduction</th>\n",
       "      <td>Yes, we can conclude that some roses fade quic...</td>\n",
       "      <td>Error: 429 You exceeded your current quota, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long-Context Understanding</th>\n",
       "      <td>The key difference between supervised and unsu...</td>\n",
       "      <td>Error: 429 You exceeded your current quota, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematical Proof</th>\n",
       "      <td>6 units\\n\\nThe area of a circle is given by th...</td>\n",
       "      <td>Error: 429 You exceeded your current quota, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical diagnosis</th>\n",
       "      <td>Most likely a urinary tract infection (UTI).\\n...</td>\n",
       "      <td>Error: 429 You exceeded your current quota, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legal case</th>\n",
       "      <td>Mary is most likely to win. John and Mary form...</td>\n",
       "      <td>Error: 429 You exceeded your current quota, pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         gemini-2.0-flash-exp  \\\n",
       "Logical Deduction           Yes, we can conclude that some roses fade quic...   \n",
       "Long-Context Understanding  The key difference between supervised and unsu...   \n",
       "Mathematical Proof          6 units\\n\\nThe area of a circle is given by th...   \n",
       "Medical diagnosis           Most likely a urinary tract infection (UTI).\\n...   \n",
       "Legal case                  Mary is most likely to win. John and Mary form...   \n",
       "\n",
       "                                                               gemini-1.5-pro  \n",
       "Logical Deduction           Error: 429 You exceeded your current quota, pl...  \n",
       "Long-Context Understanding  Error: 429 You exceeded your current quota, pl...  \n",
       "Mathematical Proof          Error: 429 You exceeded your current quota, pl...  \n",
       "Medical diagnosis           Error: 429 You exceeded your current quota, pl...  \n",
       "Legal case                  Error: 429 You exceeded your current quota, pl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Gemini 모델 비교 (모델별 thinking 요구사항 대응) =====\n",
    "import os, pandas as pd\n",
    "from IPython.display import display\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab 환경 체크\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# ---- 환경 ----\n",
    "if IN_COLAB:\n",
    "    API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "else:\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()  # 현재 디렉토리에서 .env 파일 자동 탐색\n",
    "    except ImportError:\n",
    "        print(\"python-dotenv가 설치되지 않았습니다. 환경변수에서 직접 읽습니다.\")\n",
    "    API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY 환경변수를 설정해주세요\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# ---- 비교 모델 ----\n",
    "models = [\"gemini-2.0-flash-exp\", \"gemini-1.5-pro\"]\n",
    "\n",
    "# ---- 태스크 ----\n",
    "tasks = {\n",
    "    \"Logical Deduction\": \"\"\"If all roses are flowers and some flowers fade quickly, can we conclude that some roses fade quickly? Explain your reasoning.\"\"\",\n",
    "    \"Long-Context Understanding\": \"\"\"Summarize the key differences between supervised and unsupervised learning in machine learning.\"\"\",\n",
    "    \"Mathematical Proof\": \"\"\"If the area of a circle is 36π square units, what is the radius of the circle?\n",
    "Show the answer first, then a brief derivation.\"\"\",\n",
    "    \"Medical diagnosis\": \"\"\"A 25-year-old woman has frequent, painful urination and a burning sensation while urinating. Which condition is most likely responsible?\n",
    "Answer succinctly (≤20 words), then list 2 key differentials.\"\"\",\n",
    "    \"Legal case\": \"\"\"John signs a written contract with Mary to buy her car for $5,000.\n",
    "The next day, John changes his mind without any valid reason and refuses to pay.\n",
    "If Mary sues for breach of contract, who is most likely to win? Explain briefly (≤100 words).\"\"\"\n",
    "}\n",
    "\n",
    "def analyze_text_with_gemini(model_name: str, prompt: str,\n",
    "                             temperature: float = 0.2,\n",
    "                             max_tokens: int = 700) -> str:\n",
    "    \"\"\"Gemini API를 사용한 텍스트 분석\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        generation_config = genai.GenerationConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        return (response.text or \"\").strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# ---- 실행 ----\n",
    "results = {}\n",
    "for task_name, task_prompt in tasks.items():\n",
    "    print(f\"\\n📝 Running Task: {task_name}...\\n\")\n",
    "    task_results = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        print(f\"🤖 {model_name} ...\")\n",
    "        response = analyze_text_with_gemini(\n",
    "            model_name=model_name,\n",
    "            prompt=task_prompt,\n",
    "            temperature=0.2 if task_name != \"Long-Context Understanding\" else 0.3,\n",
    "            max_tokens=900 if task_name == \"Long-Context Understanding\" else 700,\n",
    "        )\n",
    "        task_results[model_name] = response[:1000]\n",
    "\n",
    "    results[task_name] = task_results\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_KF1-_bWnAV"
   },
   "source": [
    "# DIY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5HNCeD61WnwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Running Task: RLDM_Addiction_Mechanisms...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gpt-4o-mini ...\n",
      "\n",
      "📝 Running Task: NF_Pipeline_Design...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gpt-4o-mini ...\n",
      "\n",
      "📝 Running Task: NIBS_Target_Selection...\n",
      "\n",
      "🤖 gemini-2.0-flash-exp ...\n",
      "🤖 gpt-4o-mini ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gemini-2.0-flash-exp</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RLDM_Addiction_Mechanisms</th>\n",
       "      <td>Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 26.197084731s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 26\\n}\\n]</td>\n",
       "      <td>Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NF_Pipeline_Design</th>\n",
       "      <td>Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 23.232995614s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]</td>\n",
       "      <td>Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIBS_Target_Selection</th>\n",
       "      <td>Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 20.676892226s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 20\\n}\\n]</td>\n",
       "      <td>Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     gemini-2.0-flash-exp  \\\n",
       "RLDM_Addiction_Mechanisms  Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 26.197084731s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 26\\n}\\n]   \n",
       "NF_Pipeline_Design         Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 23.232995614s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]   \n",
       "NIBS_Target_Selection      Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50\\nPlease retry in 20.676892226s. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-2.0-flash-exp\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 50\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 20\\n}\\n]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                     gpt-4o-mini  \n",
       "RLDM_Addiction_Mechanisms  Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}  \n",
       "NF_Pipeline_Design         Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}  \n",
       "NIBS_Target_Selection      Error(OpenAI): Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 여러 복잡한 어려운 과제를 정의하고 비교 해보기\n",
    "# 다른 모델의 API KEY가 있을 경우 모델 별로 비교하기\n",
    "load_dotenv() \n",
    "# ---- 비교 모델 ----\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "def call_openai_model(model_name: str, prompt: str, temperature: float = 0.2, max_tokens: int = 900) -> str:\n",
    "    try:\n",
    "        import openai\n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        # Responses API (새 SDK) 사용 예시가 환경에 따라 다를 수 있으므로 가장 단순한 chat.completions 예시:\n",
    "        client = openai.OpenAI()\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error(OpenAI): {e}\"\n",
    "\n",
    "models = [\"gemini-2.0-flash-exp\", \"gpt-4o-mini\"]\n",
    "\n",
    "# ---- 태스크 ----\n",
    "tasks = {\n",
    "\"RLDM_Addiction_Mechanisms\": (\n",
    "        \"중독(addiction) 맥락에서 RLDM 메커니즘 2–3개(RPE, model-based vs model-free weight, reward sensitivity)를 요약하고, \"\n",
    "        \"각 메커니즘에 대해 (1) 검증 가능한 가설 1개, (2) behavioral + fMRI 측정지표 2개, (3) 예상 뇌 영역 2개를 제시하라. \"\n",
    "        \"간단 수식 1개(δ = r + γ·V(s′) − V(s)) 포함. 한국어로, 핵심 용어는 영문 병기.\"\n",
    "    ),\n",
    "    \"NF_Pipeline_Design\": (\n",
    "        \"금연 맥락의 rtfMRI neurofeedback 파이프라인을 설계하라(측정→추정→피드백→조절→학습). \"\n",
    "        \"Target signal 1개(striatal RPE proxy 또는 vmPFC value), 세션 구조(n×duration), 피드백 스케일링/레이턴시, \"\n",
    "        \"1차/2차 지표를 제시하고, latency/표적특이성/전략의존성 리스크와 완화책을 간단히 기술. 한국어+영문 병기.\"\n",
    "    ),\n",
    "    \"NIBS_Target_Selection\": (\n",
    "        \"중독 관련 실행통제/가치평가 결함을 겨냥한 NIBS(TMS/tDCS) 타겟 2곳을 제안하라. \"\n",
    "        \"각 타겟에 대해 이론 근거(RLDM 연결), 프로토콜 개요(빈도/강도/세션), 1차 지표(behavior+neural), \"\n",
    "        \"안전/윤리 체크포인트를 불릿으로 제시. 한국어+영문 병기.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- 모델 라우팅 도우미 ---\n",
    "def run_model(model_name: str, prompt: str, temperature: float = 0.2, max_tokens: int = 900) -> str:\n",
    "    if model_name.startswith(\"gemini\"):\n",
    "        # Gemini는 기존 함수 사용\n",
    "        return analyze_text_with_gemini(\n",
    "            model_name=model_name,\n",
    "            prompt=prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "    else:\n",
    "        # OpenAI 라우팅 (gpt-*, o*- 계열)\n",
    "        return call_openai_model(\n",
    "            model_name=model_name,\n",
    "            prompt=prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "\n",
    "# ---- 실행 ----\n",
    "results = {}\n",
    "for task_name, task_prompt in tasks.items():\n",
    "    print(f\"\\n📝 Running Task: {task_name}...\\n\")\n",
    "    task_results = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        print(f\"🤖 {model_name} ...\")\n",
    "        response = run_model(\n",
    "            model_name=model_name,\n",
    "            prompt=task_prompt,\n",
    "            temperature=0.2,\n",
    "            max_tokens=700,\n",
    "        )\n",
    "        task_results[model_name] = (response or \"\")[:1000]\n",
    "\n",
    "    results[task_name] = task_results\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "pd.set_option(\"display.max_colwidth\", None)  # 열 내용 줄임없이 전체 표시\n",
    "pd.set_option(\"display.max_rows\", None)      # 행도 다 보여줌\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
